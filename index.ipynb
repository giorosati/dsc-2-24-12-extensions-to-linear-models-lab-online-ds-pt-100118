{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(boston.target,columns = [\"target\"])\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "X_scaled = preprocessing.scale(df)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = df.columns)\n",
    "\n",
    "all_data = pd.concat([y,X_scaled], axis = 1)\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_scaled, y, scoring=\"r2\", cv=crossvalidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176324491383005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))\n",
    "\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combinations:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "        \n",
    "print(\"Top 7 interactions: %s\" %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_inter = X_scaled.copy()\n",
    "ls_interactions = sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7]\n",
    "for inter in ls_interactions:\n",
    "    df_inter[inter[0]+\"_\"+inter[1]] =df[inter[0]]*df[inter[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>32.74350</td>\n",
       "      <td>1946.200</td>\n",
       "      <td>6.575</td>\n",
       "      <td>100.5975</td>\n",
       "      <td>15.18825</td>\n",
       "      <td>3.537350</td>\n",
       "      <td>428.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>58.68794</td>\n",
       "      <td>1553.882</td>\n",
       "      <td>12.842</td>\n",
       "      <td>114.2938</td>\n",
       "      <td>45.39647</td>\n",
       "      <td>3.011449</td>\n",
       "      <td>506.6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>28.95555</td>\n",
       "      <td>1738.770</td>\n",
       "      <td>14.370</td>\n",
       "      <td>127.8930</td>\n",
       "      <td>50.79795</td>\n",
       "      <td>3.369765</td>\n",
       "      <td>439.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>20.57412</td>\n",
       "      <td>1553.556</td>\n",
       "      <td>20.994</td>\n",
       "      <td>130.8626</td>\n",
       "      <td>15.25564</td>\n",
       "      <td>3.205084</td>\n",
       "      <td>320.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>38.09351</td>\n",
       "      <td>1586.634</td>\n",
       "      <td>21.441</td>\n",
       "      <td>133.6489</td>\n",
       "      <td>15.58046</td>\n",
       "      <td>3.273326</td>\n",
       "      <td>387.3674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  32.74350   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  58.68794   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  28.95555   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  20.57412   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  38.09351   \n",
       "\n",
       "     RM_TAX  RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0  1946.200   6.575    100.5975  15.18825  3.537350  428.6900  \n",
       "1  1553.882  12.842    114.2938  45.39647  3.011449  506.6169  \n",
       "2  1738.770  14.370    127.8930  50.79795  3.369765  439.0035  \n",
       "3  1553.556  20.994    130.8626  15.25564  3.205084  320.5084  \n",
       "4  1586.634  21.441    133.6489  15.58046  3.273326  387.3674  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in df.columns:\n",
    "    for degree in [2,3,4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X = poly.fit_transform(df[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X)], axis = 1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score,3)))\n",
    "print(\"Top 10 polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "CHAS       0.718\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.719\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort = False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RM and LSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in [\"RM\", \"LSTAT\"]:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X = poly.fit_transform(df[[col]])\n",
    "    colnames= [col, col+\"_\"+\"2\", col+\"_\"+\"3\", col+\"_\"+\"4\"]\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1),pd.DataFrame(X, columns=colnames)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.537350</td>\n",
       "      <td>428.6900</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>3.011449</td>\n",
       "      <td>506.6169</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>3.369765</td>\n",
       "      <td>439.0035</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.205084</td>\n",
       "      <td>320.5084</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273326</td>\n",
       "      <td>387.3674</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO     ...         NOX_RM    RM_AGE     RM  \\\n",
       "0 -0.982843 -0.666608 -1.459000     ...       3.537350  428.6900  6.575   \n",
       "1 -0.867883 -0.987329 -0.303094     ...       3.011449  506.6169  6.421   \n",
       "2 -0.867883 -0.987329 -0.303094     ...       3.369765  439.0035  7.185   \n",
       "3 -0.752922 -1.106115  0.113032     ...       3.205084  320.5084  6.998   \n",
       "4 -0.752922 -1.106115  0.113032     ...       3.273326  387.3674  7.147   \n",
       "\n",
       "        RM_2        RM_3         RM_4  LSTAT  LSTAT_2     LSTAT_3      LSTAT_4  \n",
       "0  43.230625  284.241359  1868.886938   4.98  24.8004  123.505992   615.059840  \n",
       "1  41.229241  264.732956  1699.850313   9.14  83.5396  763.551944  6978.864768  \n",
       "2  51.624225  370.920057  2665.060607   4.03  16.2409   65.450827   263.766833  \n",
       "3  48.972004  342.706084  2398.257176   2.94   8.6436   25.412184    74.711821  \n",
       "4  51.079609  365.065966  2609.126456   5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061116489236919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model = np.mean(cross_val_score(regression, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNEqAiIiIRgkQERHRKAEiIiIa/QdJJHbLSPVucgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7549021627363743\n",
      "Testing r^2: 0.6817209067655855\n",
      "Training MSE: 18.547198079608474\n",
      "Testing MSE: 33.89685880019981\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8470780724087217\n",
      "Testing r^2: 0.6977601871453494\n",
      "Training MSE: 13.63267890354518\n",
      "Testing MSE: 21.239151511929528\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8431076810013899\n",
      "Testing r^2: 0.711801580878654\n",
      "Training MSE: 13.986631224380536\n",
      "Testing MSE: 20.252427472751627\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
